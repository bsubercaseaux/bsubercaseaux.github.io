%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Bernardo Roa at 2023-01-23 14:25:13 -0800 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{bpms2020,
	abstract = {In spite of several claims stating that some models are more interpretable than others -- e.g., "linear models are more interpretable than deep neural networks" -- we still lack a principled notion of interpretability to formally compare among different classes of models. We make a step towards such a notion by studying whether folklore interpretability claims have a correlate in terms of computational complexity theory. We focus on local post-hoc explainability queries that, intuitively, attempt to answer why individual inputs are classified in a certain way by a given model. In a nutshell, we say that a class \mathcal{C}_1 of models is more interpretable than another class \mathcal{C}_2, if the computational complexity of answering post-hoc queries for models in \mathcal{C}_2 is higher than for those in \mathcal{C}_1. We prove that this notion provides a good theoretical counterpart to current beliefs on the interpretability of models; in particular, we show that under our definition and assuming standard complexity-theoretical assumptions (such as P\neqNP), both linear and tree-based models are strictly more interpretable than neural networks. Our complexity analysis, however, does not provide a clear-cut difference between linear and tree-based models, as we obtain different results depending on the particular post-hoc explanations considered. Finally, by applying a finer complexity analysis based on parameterized complexity, we are able to prove a theoretical result suggesting that shallow neural networks are more interpretable than deeper ones.},
	arxiv = {2010.12265},
	author = {Pablo Barcel{\'{o}} and Mika{\"{e}}l Monet and Jorge P{\'{e}}rez and Bernardo Subercaseaux},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	bibtex_show = {true},
	biburl = {https://dblp.org/rec/conf/nips/BarceloM0S20.bib},
	booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual},
	editor = {Hugo Larochelle and Marc'Aurelio Ranzato and Raia Hadsell and Maria{-}Florina Balcan and Hsuan{-}Tien Lin},
	pages = {15487--15498},
	pdf = {https://arxiv.org/pdf/2010.12265.pdf},
	publisher = {Curran Associates, Inc.},
	selected = {true},
	timestamp = {Tue, 19 Jan 2021 15:56:49 +0100},
	title = {Model Interpretability through the lens of Computational Complexity},
	url = {https://proceedings.neurips.cc/paper/2020/hash/b1adda14824f50ef24ff1c05bb66faf3-Abstract.html},
	year = {2020},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper/2020/hash/b1adda14824f50ef24ff1c05bb66faf3-Abstract.html}}

@article{bps2020,
	abstract = {Despite the growing interest in interpretability for machine learning models, there
seems to be a gap between the world of researchers and that of practitioners and
data scientists. Declarative languages, tailored for interactive interpretability and
bias detection of models, could be a step towards shortening such a gap. Based
on requirements often posed over interpretability tasks, it is desirable for such
languages to be interactive, model agnostic, faithful to the models, and have
clear and well-understood semantics and complexity. A reasonable way to meet
several of these requirements is by having a language strongly rooted in logic. As
a first step towards the design of such language, we study how interpretability
and bias detection queries can be expressed in first-order logic (FO) --arguably,
one of the most prominent logics in different areas of computer science-- over a
suitable encoding of machine learning models. We then study the computational
complexity of evaluating FO formulae over linear-based, tree-based and deep
models. Evaluation is shown to be easier for decision trees and perceptrons than
it is for deep neural networks, which seems validated by folklore assumptions
of the field. Finally, we discuss possible extensions to the underlying logical
structure and how they enhance expressiveness, as well as possible directions
towards tractability.},
	author = {Pablo Barcel{\'{o}} and Jorge P{\'{e}}rez and Bernardo Subercaseaux},
	bibtex_show = {true},
	journal = {AFCI workshop at NeurIPS 2020. Algorithmic Fairness through the Lens of Causality and Interpretability},
	pdf = {../pdf/afci2020.pdf},
	selected = {true},
	title = {Foundations of Languages for Interpretability and Bias Detection},
	year = {2020}}

@inproceedings{bhps2020,
	abstract = {We study the expressive power of the LARA language -- a recently proposed unified model for expressing relational and linear algebra operations -- both in terms of traditional database query languages and some analytic tasks often performed in machine learning pipelines. We start by showing LARA to be expressive complete with respect to first-order logic with aggregation. Since LARA is parameterized by a set of user-defined functions which allow to transform values in tables, the exact expressive power of the language depends on how these functions are defined. We distinguish two main cases depending on the level of genericity queries are enforced to satisfy. Under strong genericity assumptions the language cannot express matrix convolution, a very important operation in current machine learning operations. This language is also local, and thus cannot express operations such as matrix inverse that exhibit a recursive behavior. For expressing convolution, one can relax the genericity requirement by adding an underlying linear order on the domain. This, however, destroys locality and turns the expressive power of the language much more difficult to understand. In particular, although under complexity assumptions the resulting language can still not express matrix inverse, a proof of this fact without such assumptions seems challenging to obtain.},
	arxiv = {1909.11693},
	author = {Pablo Barcel{\'{o}} and Nelson Higuera and Jorge P{\'{e}}rez and Bernardo Subercaseaux},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	bibtex_show = {true},
	biburl = {https://dblp.org/rec/conf/icdt/BarceloH0S20.bib},
	booktitle = {23rd International Conference on Database Theory, {ICDT} 2020, March 30-April 2, 2020, Copenhagen, Denmark},
	doi = {10.4230/LIPIcs.ICDT.2020.6},
	editor = {Carsten Lutz and Jean Christoph Jung},
	pages = {6:1--6:20},
	pdf = {https://arxiv.org/pdf/1909.11693.pdf},
	publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
	selected = {true},
	series = {LIPIcs},
	timestamp = {Thu, 19 Mar 2020 10:24:23 +0100},
	title = {On the Expressiveness of {LARA:} {A} Unified Language for Linear and Relational Algebra},
	url = {https://doi.org/10.4230/LIPIcs.ICDT.2020.6},
	volume = {155},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.4230/LIPIcs.ICDT.2020.6}}

@inproceedings{abrs2022,
	abstract = {Formal XAI (explainable AI) is a growing area that focuses on computing explanations with mathematical guarantees for the decisions made by ML models. Inside formal XAI, one of the most studied cases is that of explaining the choices taken by decision trees, as they are traditionally deemed as one of the most interpretable classes of models. Recent work has focused on studying the computation of sufficient reasons, a kind of explanation in which given a decision tree $T$ and an instance $x$, one explains the decision $T(x)$ by providing a subset $y$ of the features of $x$ such that for any other instance $z$ compatible with $y$, it holds that  $T(z) = T(x)$, intuitively meaning that the features in $y$ are already enough to fully justify the classification of $x$ by $T$. 
It has been argued, however, that sufficient reasons constitute a restrictive notion of explanation. For such a reason, the community has started to study their probabilistic counterpart, in which one requires that the probability of $T(z) = T(x)$ must be at least some value $\delta \in (0, 1]$, where $z$ is a random instance that is compatible with $y$. Our paper settles the computational complexity of $\delta$-sufficient-reasons over decision trees, showing that both (1) finding $\delta$-sufficient-reasons  that are minimal in size, and (2) finding $\delta$-sufficient-reasons that are minimal inclusion-wise, do not admit polynomial-time algorithms (unless P = NP).
   This is in stark contrast with the deterministic case ($\delta = 1$) where inclusion-wise minimal sufficient-reasons are easy to compute. By doing this, we answer two open problems originally raised by Izza et al., and extend the hardness of explanations for Boolean circuits presented by W{\"a}ldchen et al. to the more restricted case of decision trees. On the positive side, we identify structural restrictions of decision trees that make the problem tractable, and show how SAT solvers might be able to tackle these problems in practical settings.},
	arxiv = {https://arxiv.org/abs/2207.12213},
	author = {Marcelo Arenas and Pablo Barcelo and Miguel Romero Orth and Bernardo Subercaseaux},
	bibtex_show = {true},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
	pdf = {https://arxiv.org/pdf/2207.12213.pdf},
	selected = {true},
	title = {On Computing Probabilistic Explanations for Decision Trees},
	url = {https://openreview.net/forum?id=zD65Zdh6ZhI},
	year = {2022},
	bdsk-url-1 = {https://openreview.net/forum?id=zD65Zdh6ZhI}}

@inproceedings{gpss2022,
	abstract = {The growing body of work in learning-augmented online algorithms studies how online algorithms can be improved when given access to ML predictions about the future. Motivated by ML models that give a confidence parameter for their predictions, we study online algorithms with predictions that are $\epsilon$-accurate: namely, each prediction is correct with probability (at least) $\epsilon$, but can be arbitrarily inaccurate with the remaining probability. We show that even with predictions that are accurate with a small probability and arbitrarily inaccurate otherwise, we can dramatically outperform worst-case bounds for a range of classical online problems including caching, online set cover, and online facility location. Our main results are an $O(\log(1/\varepsilon))$-competitive algorithm for caching, and a simple $O(1/\varepsilon)$-competitive algorithm for a large family of covering problems, including set cover and facility location, with $\epsilon$-accurate predictions.},
	author = {Anupam Gupta and Debmalya Panigrahi and Bernardo Subercaseaux and Kevin Sun},
	bibtex_show = {true},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
	pdf = {https://openreview.net/pdf?id=HFkxZ_V0sBQ},
	selected = {true},
	title = {Augmenting Online Algorithms with \$$\varepsilon\$$-Accurate Predictions},
	url = {https://openreview.net/forum?id=HFkxZ_V0sBQ},
	year = {2022},
	bdsk-url-1 = {https://openreview.net/forum?id=HFkxZ_V0sBQ}}

@inproceedings{bs2021,
	abstract = {The game of Hangman is a classical asymmetric two player game in which one player, the setter, chooses a secret word from a language, that the other player, the guesser, tries to discover through single letter matching queries, answered by all occurrences of this letter if any. In the Evil Hangman variant, the setter can change the secret word during the game, as long as the new choice is consistent with the information already given to the guesser. We show that a greedy strategy for Evil Hangman can perform arbitrarily far from optimal, and most importantly, that playing optimally as an Evil Hangman setter is computationally difficult. The latter result holds even assuming perfect knowledge of the language, for several classes of languages, ranging from Finite to Turing Computable. The proofs are based on reductions to Dominating Set on 3-regular graphs and to the Membership problem, combinatorial problems already known to be computationally hard.},
	arxiv = {2003.10000},
	author = {J{\'{e}}r{\'{e}}my Barbay and Bernardo Subercaseaux},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	bibtex_show = {true},
	biburl = {https://dblp.org/rec/conf/fun/BarbayS21.bib},
	booktitle = {10th International Conference on Fun with Algorithms, {FUN} 2021, May 30 to June 1, 2021, Favignana Island, Sicily, Italy},
	doi = {10.4230/LIPIcs.FUN.2021.23},
	editor = {Martin Farach{-}Colton and Giuseppe Prencipe and Ryuhei Uehara},
	pages = {23:1--23:12},
	pdf = {https://arxiv.org/pdf/2003.10000.pdf},
	publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
	selected = {true},
	series = {LIPIcs},
	timestamp = {Mon, 21 Dec 2020 13:23:22 +0100},
	title = {The Computational Complexity of Evil Hangman},
	url = {https://doi.org/10.4230/LIPIcs.FUN.2021.23},
	volume = {157},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.4230/LIPIcs.FUN.2021.23}}

@inproceedings{bhps2019,
	abstract = {Tensors are one of the most widely used data structures in modern Machine Learning applications. Although they provide a flexible way of storing and accessing data, they often expose too many low-level details that may result in error prone code that is difficult to maintain and extend. Abstracting low-level functionalities into high-level operators in the form of a query language is a task in which the Data Management community has extensive experience. It is thus important to understand how such an experience can be applied in the design of useful languages for tensor manipulation.

In this short paper we study a matrix and a tensor query language that have been recently proposed in the database literature. We show, by using examples, how these proposals are in line with the practical interest in rethinking tensor abstractions. On the technical side, we compare the two languages in terms of operators that naturally arise in Machine Learning pipelines, such as convolution, matrix-inverse, and Einstein summation. We hope our results to provide a theoretical kick-off for the discussion on the design of core declarative query languages for tensors.},
	author = {Pablo Barcel{\'{o}} and Nelson Higuera and Jorge P{\'{e}}rez and Bernardo Subercaseaux},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	bibtex_show = {true},
	biburl = {https://dblp.org/rec/conf/sigmod/BarceloH0S19.bib},
	booktitle = {Proceedings of the 3rd International Workshop on Data Management for End-to-End Machine Learning, DEEM@SIGMOD 2019, Amsterdam, The Netherlands, June 30, 2019},
	doi = {10.1145/3329486.3329498},
	editor = {Sebastian Schelter and Neoklis Polyzotis and Stephan Seufert and Manasi Vartak},
	html = {https://dl.acm.org/doi/10.1145/3329486.3329498},
	pages = {9:1--9:5},
	pdf = {../pdf/deem19.pdf},
	publisher = {{ACM}},
	selected = {true},
	timestamp = {Wed, 05 Jun 2019 14:54:54 +0200},
	title = {Expressiveness of Matrix and Tensor Query Languages in terms of {ML} Operators},
	url = {https://doi.org/10.1145/3329486.3329498},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1145/3329486.3329498}}

@article{clps2016,
	abstract = {The wavelet tree is a data structure to succinctly represent sequences of elements over
a fixed but potentially large alphabet. It is a very versatile data structure which exhibits interesting properties even when its compression capabilities are not considered, efficiently supporting
several queries. Although the wavelet tree was proposed more than a decade ago, it has not yet
been widely used by the competitive programming community. This paper tries to fill the gap
by showing how this data structure can be used in classical competitive programming problems,
discussing some implementation details, and presenting a performance analysis focused in a
competitive programming setting.},
	author = {Robinson Castro and Nico Lehmann and Jorge P{\'e}rez and Bernardo Subercaseaux},
	bibtex_show = {true},
	doi = {10.15388/ioi.2016.02},
	journal = {Olympiads in Informatics},
	month = jul,
	number = {1},
	pages = {19--37},
	pdf = {https://ioinformatics.org/journal/v10_2016_19_37.pdf},
	publisher = {Vilnius University Press},
	select = {true},
	title = {Wavelet Trees for Competitive Programming},
	url = {https://doi.org/10.15388/ioi.2016.02},
	volume = {10},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.15388/ioi.2016.02}}

@article{abbps2021,
	abstract = {Several queries and scores have been proposed to explain individual predictions
made by ML models. Examples include queries based on ``anchors", which are
parts of an instance that are sufficient to justify its classification, and ''feature perturbation" scores such as SHAP. 
Given the need for flexible, reliable, and easy-to-apply interpretability methods for ML models, we foresee the need for developing declarative languages to naturally specify different explainability queries. We
do this in a principled way by rooting such a language in a logic called FOIL,
that allows for expressing many simple but important explainability queries, and
might serve as a core for more expressive interpretability languages. We study the
computational complexity of FOIL queries over classes of ML models often deemed
to be easily interpretable: decision trees and more general decision diagrams. Since
the number of possible inputs for an ML model is exponential in its dimension,
tractability of the FOIL evaluation problem is delicate, but can be achieved by either
restricting the structure of the models, or the fragment of FOIL being evaluated.
We also present a prototype implementation of FOIL wrapped in a high-level
declarative language, and perform experiments showing that such a language can
be used in practice.},
	archiveprefix = {arXiv},
	arxiv = {2110.02376},
	author = {Marcelo Arenas and Daniel Baez and Pablo Barcel{\'o} and Jorge P{\'e}rez and Bernardo Subercaseaux},
	bibtex_show = {true},
	booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021},
	date-modified = {2023-01-23 14:25:10 -0800},
	eprint = {2110.02376},
	journal = {Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021},
	pdf = {https://arxiv.org/pdf/2110.02376.pdf},
	primaryclass = {cs.AI},
	publisher = {Curran Associates, Inc.},
	selected = {true},
	title = {Foundations of Symbolic Languages for Model Interpretability},
	url = {https://arxiv.org/abs/2110.02376},
	year = {2021},
	bdsk-url-1 = {https://arxiv.org/abs/2110.02376}}

@inproceedings{ls2022,
	abstract = {Wordle is a single-player word-guessing game where the goal is to discover a secret word w that has been chosen from a dictionary D. In order to discover w, the player can make at most 𝓁 guesses, which must also be words from D, all words in D having the same length k. After each guess, the player is notified of the positions in which their guess matches the secret word, as well as letters in the guess that appear in the secret word in a different position. We study the game of Wordle from a complexity perspective, proving NP-hardness of its natural formalization: to decide given a dictionary D and an integer 𝓁 if the player can guarantee to discover the secret word within 𝓁 guesses. Moreover, we prove that hardness holds even over instances where words have length k = 5, and that even in this case it is NP-hard to approximate the minimum number of guesses required to guarantee discovering the secret word. We also present results regarding its parameterized complexity and offer some related open problems.},
	address = {Dagstuhl, Germany},
	annote = {Keywords: wordle, np-hardness, complexity},
	arxiv = {https://arxiv.org/abs/2203.16713},
	author = {Lokshtanov, Daniel and Subercaseaux, Bernardo},
	bibtex_show = {true},
	booktitle = {11th International Conference on Fun with Algorithms (FUN 2022)},
	doi = {10.4230/LIPIcs.FUN.2022.19},
	editor = {Fraigniaud, Pierre and Uno, Yushi},
	isbn = {978-3-95977-232-7},
	issn = {1868-8969},
	pages = {19:1--19:8},
	pdf = {https://arxiv.org/pdf/2203.16713.pdf},
	publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
	selected = {true},
	series = {Leibniz International Proceedings in Informatics (LIPIcs)},
	title = {{Wordle Is NP-Hard}},
	url = {https://drops.dagstuhl.de/opus/volltexte/2022/15989},
	urn = {urn:nbn:de:0030-drops-159893},
	volume = {226},
	year = {2022},
	bdsk-url-1 = {https://drops.dagstuhl.de/opus/volltexte/2022/15989},
	bdsk-url-2 = {https://doi.org/10.4230/LIPIcs.FUN.2022.19}}

@inproceedings{sh2022,
	abstract = {A packing k-coloring of a graph G = (V, E) is a mapping from V to {1, ..., k} such that any pair of vertices u, v that receive the same color c must be at distance greater than c in G. Arguably the most fundamental problem regarding packing colorings is to determine the packing chromatic number of the infinite square grid. A sequence of previous works has proved this number to be between 13 and 15. Our work improves the lower bound to 14. Moreover, we present a new encoding that is asymptotically more compact than the previously used ones.},
	address = {Dagstuhl, Germany},
	annote = {Keywords: packing coloring, SAT solvers, encodings},
	author = {Subercaseaux, Bernardo and Heule, Marijn J.H.},
	bibtex_show = {true},
	booktitle = {25th International Conference on Theory and Applications of Satisfiability Testing (SAT 2022)},
	doi = {10.4230/LIPIcs.SAT.2022.21},
	editor = {Meel, Kuldeep S. and Strichman, Ofer},
	isbn = {978-3-95977-242-6},
	issn = {1868-8969},
	pages = {21:1--21:16},
	pdf = {https://drops.dagstuhl.de/opus/volltexte/2022/15989/pdf/LIPIcs-FUN-2022-19.pdf},
	publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
	selected = {true},
	series = {Leibniz International Proceedings in Informatics (LIPIcs)},
	title = {{The Packing Chromatic Number of the Infinite Square Grid Is at Least 14}},
	url = {https://drops.dagstuhl.de/opus/volltexte/2022/16695},
	urn = {urn:nbn:de:0030-drops-166951},
	volume = {236},
	year = {2022},
	bdsk-url-1 = {https://drops.dagstuhl.de/opus/volltexte/2022/16695},
	bdsk-url-2 = {https://doi.org/10.4230/LIPIcs.SAT.2022.21}}
